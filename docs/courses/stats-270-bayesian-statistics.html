<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <title>
    STATS 270: Bayesian Statistics
  </title>
  <meta
    name="description"
    content="A collection of work and research by Daniel jenson."
  />

  <!-- Google Fonts -->
  <link
    href="//fonts.googleapis.com/css?family=Lato:400,400italic"
    rel="stylesheet"
    type="text/css"
  />

  <!-- https://docs.mathjax.org/en/latest/input/tex/extensions/index.html -->
  <script>
    MathJax = {
      loader: {
        load: [
          "[tex]/ams",
          "[tex]/gensymb",
          "[tex]/mathtools",
          "[tex]/physics",
        ],
      },
      tex: {
        packages: { "[+]": ["ams", "gensymb", "mathtools", "physics"] },
        inlineMath: [
          ["$", "$"],
          ["\\(", "\\)"],
        ],
      },
      svg: {
        fontCache: "global",
      },
    };
  </script>
  <!-- https://www.mathjax.org/#gettingstarted -->
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script
    id="MathJax-script"
    async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
  ></script>
  <link rel="stylesheet" type="text/css" href="/notes/assets/css/main.css">

  <link
    rel="canonical"
    href="http://localhost:4000/notes/courses/stats-270-bayesian-statistics.html"
  />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
  <nav class="group">
     
    <a href="/notes/books">books</a>
      
    <a href="/notes/papers">papers</a>
      
    <a href="/notes/courses">courses</a>
      
    <a href="/notes/mindmaps">mindmaps</a>
     
    <button
      type="button"
      id="theme-toggle"
      onclick="modeSwitcher()"
      style="cursor: pointer"
    ></button>
  </nav>
  <script src="/notes/assets/js/theme-toggle.js"></script>
</header>

    <article class="group">
<h1>STATS 270: Bayesian Statistics</h1>

<p class="subtitle"></p>

<ul id="toc" class="section-nav">
<li class="toc-entry toc-h1"><a href="#typed-notes">Typed Notes</a>
<ul>
<li class="toc-entry toc-h2"><a href="#terminology">Terminology</a>
<ul>
<li class="toc-entry toc-h3"><a href="#terms">Terms</a></li>
<li class="toc-entry toc-h3"><a href="#notation">Notation</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#chapter-1-statistical-inference">Chapter 1: Statistical Inference</a>
<ul>
<li class="toc-entry toc-h3"><a href="#likelihood-and-inference">Likelihood and Inference</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#lectures">Lectures</a>
<ul>
<li class="toc-entry toc-h2"><a href="#lecture-1">Lecture 1</a></li>
<li class="toc-entry toc-h2"><a href="#lecture-2">Lecture 2</a></li>
</ul>
</li>
</ul><h1 id="typed-notes">
<a class="anchor" href="#typed-notes" aria-hidden="true"><span class="octicon octicon-link"></span></a>Typed Notes</h1>

<h2 id="terminology">
<a class="anchor" href="#terminology" aria-hidden="true"><span class="octicon octicon-link"></span></a>Terminology</h2>

<h3 id="terms">
<a class="anchor" href="#terms" aria-hidden="true"><span class="octicon octicon-link"></span></a>Terms</h3>

<ul>
  <li>
<strong>Inference</strong>: The process of drawing reliable conclusions from
data subject to random variation. In particular, based on data, inference
draws a conclusion about a parameter $\theta$. Note that in ML/Deep Learning,
“inference” is used slightly differently and often refers to passing input
through a trained model to get predictions.</li>
  <li>
<strong>Likelihood function</strong>: Any function
$\mathcal{L}(\theta;\mathbf{y})=c(\mathbf{y})p(\theta;\mathbf{y})$ that is
proportional to $p(\theta;\mathbf{y})$ for any function $c(\mathbf{y})&gt;0$ that
is independent of the parameter $\theta$ but may depend on $\mathbf{y}$.
Typically, this is written as $\mathcal{L}(\theta\mid\mathbf{y})$, which
emphasizes that it is a function of $\theta$ conditional on observed data.
This is also written as $P(\mathbf{y}\mid\theta)$ or the probability of the
data given a value for $\theta$. Further, note that this is invariant under
linear transformations, i.e. if $\mathbf{z}=g(\mathbf{y})$, mapping $\mathbb{R}^n\to
\mathbb{R}^n$, then
$\mathcal{L}(\theta;\mathbf{z})=p\left(\theta;g^{-1}(\mathbf{z})\right)\left|\pdv{\mathbf{y}}{\mathbf{z}}\right|$
where the last term is the absolute value of the determinant of the Jacobian.</li>
  <li>
<strong>Posterior</strong>: Likelihood $\times$ Prior / Evidence, i.e.
$\frac{\mathcal{L}(\theta\mid\mathbf{y})\times P(\theta)}{\int
P(\mathbf{y}\mid\theta)P(\theta)\dd\theta}$.</li>
  <li>
<strong>Statistic</strong>: a measurable function of $\mathbf{Y}$, i.e. $S=S(\mathbf{Y})$.</li>
  <li>
<strong>Sufficient Statistic</strong>: A statistic such that no other statistic calculated
form the same sample can provide any more information about the parameter of
interest. Mathematically, $T(\mathbf{Y})$ is a sufficient statistic if
$P(\mathbf{Y}\mid T(\mathbf{Y}),\theta)=P(\mathbf{Y}\mid T(\mathbf{Y}))$.
Another way of expressing this is that if $P(\mathbf{Y}\mid T(\mathbf{Y}))$
remains the same over the set
$\mathscr{F}=\{\Pr_\theta(\mathbf{y}):\theta\in\Omega\}$, then it is
sufficient. One can think of it as $P_{T(\mathbf{Y})}(\mathbf{y})$.</li>
</ul>

<h3 id="notation">
<a class="anchor" href="#notation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Notation</h3>

<ul>
  <li>$p(\theta;\mathbf{y})$: $\theta$ given $\mathbf{y}$, not necessarily
conditional on in an event sense. This is often used in optimization.</li>
  <li>$p(\mathbf{y}\mid\theta)$: $\mathbf{y}$ conditional on the state of affairs or
event that $\theta$ has happened. This usage is restricted to statistics.</li>
  <li>$\Pr_\theta(\mathbf{y})$: Joint probability of $\mathbf{y}$ under parameters
$\theta$, equivalent to $\Pr(\mathbf{y}\mid\theta)$.</li>
  <li>$\mathcal{L}(\theta;\mathbf{y})$: The likelihood function of $\theta$ given $\mathbf{y}$.</li>
</ul>

<h2 id="chapter-1-statistical-inference">
<a class="anchor" href="#chapter-1-statistical-inference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Chapter 1: Statistical Inference</h2>

<h3 id="likelihood-and-inference">
<a class="anchor" href="#likelihood-and-inference" aria-hidden="true"><span class="octicon octicon-link"></span></a>Likelihood and Inference</h3>

<ul>
  <li>
    <p>Given $\mathbf{Y}=(Y_1,\ldots,Y_n)$ is observed, i.e.
$\mathbf{y}=(y_1,\ldots,y_n)$, our goal is to make an inferential statement
about $\theta$, the parameters of the data generating function.</p>
  </li>
  <li>
    <p>Example 1.1: Sample statistic $S=S(\mathbf{Y})=\sum_i Y_i$ with Bernoulli data</p>

    <ul>
      <li>Given a sample of $\mathbf{Y}$ where each $Y_i\sim
\operatorname{Ber}(\theta)$, then the probability of the joint distribution
is \(\Pr_\theta(\mathbf{y}) \equiv \Pr(\mathbf{y} \mid
\theta)=\prod_{i=1}^n
\theta^{y_i}(1-\theta)^{1-y_i}=\theta^s(1-\theta)^{n-s}\).</li>
      <li>$\mathbf{Y}$ Can also be viewed as following $\operatorname{Bin}(n;\theta)$,
namely $\Pr_\theta(S=s)=\binom{n}{s}\theta^s(1-\theta)^{n-s}$.</li>
      <li>Now, $\Pr_\theta(\mathbf{Y}=\mathbf{y}\mid
S=s)=\frac{\Pr_\theta(\mathbf{Y}=\mathbf{y},S=s)}{\Pr(S=s)}=\frac{\theta^s(1-\theta)^{n-s}}{\binom{n}{s}\theta^s(1-\theta)^{n-s}}=\frac{1}{\binom{n}{s}}$,
which doesn’t depend on $\theta$. Thus, $S$ is a sufficient statistic for
$\theta$.</li>
    </ul>
  </li>
</ul>

<h1 id="lectures">
<a class="anchor" href="#lectures" aria-hidden="true"><span class="octicon octicon-link"></span></a>Lectures</h1>

<h2 id="lecture-1">
<a class="anchor" href="#lecture-1" aria-hidden="true"><span class="octicon octicon-link"></span></a>Lecture 1</h2>

<h2 id="lecture-2">
<a class="anchor" href="#lecture-2" aria-hidden="true"><span class="octicon octicon-link"></span></a>Lecture 2</h2>

</article>
    <span class="print-footer"
  >STATS 270: Bayesian Statistics - Daniel Jenson
</span>
 <footer>
  <hr class="slender">
  <ul class="footer-links">
    <li><a href="daniel.a.jenson@gmail.com"><span class="icon-mail3"></span></a></li>    
    
      <li>
        <a href="https://www.linkedin.com/in/daniel-jenson-7a002a30/"><span class="icon-linkedin"></span></a>
      </li>
    
      <li>
        <a href="https://github.com/danjenson"><span class="icon-github"></span></a>
      </li>
      
  </ul>
<div class="credits">
<span>&copy; 2022 &nbsp;&nbsp;DANIEL JENSON</span></br> <br>
<span>This site created with the <a href="//github.com/danjenson/et">Edward Tufte theme for Daniel Jenson </a> in <a href="//jekyllrb.com">Jekyll</a>.</span> 
</div>  
</footer>

  </body>
</html>
